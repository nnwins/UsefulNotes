# 笔记整理

- 作者：王冰
- 类别：深度学习，自然语言处理，编程相关，论文写作，其他
- 时间：2020年5月

[TOC]

## 深度学习

- [邱锡鹏老师-神经网络与深度学习](https://nndl.github.io/)  复旦大学邱老师的书，刚出的，这些是电子版的，强烈推荐，很好的基础理论介绍的资料。
- [某深度学习课程大纲](deeplearning\某深度学习课程大纲.pdf) 这套课程是我研一入学第一个月买的一个DL课程，算是在深度学习的一门启蒙课程吧。一般刚接触DL的人大致都需要熟悉这些方面的知识。现在想想当时真是傻，花3500买门网课，最后也没完全看完。不过外国人的上课方式就是生动有趣，分分钟让你上头。这年头很多优质的资料都是免费的，但需要你投入足够多的时间去消化。而这些入门课程，在某种程度上，对原始内容进行了某种程度降维，更加容易理解罢了。
- [某课程视频链接youtube](deeplearning\某课程视频链接youtube.pdf) 这里我当时只保存了一部分链接，感兴趣的可以看看。
- [学习率如何调节小例子](deeplearning\学习率如何调节小例子.pdf) 这是课程的一个小例子，教你学会如何根据loss来调节学习率，就是这种小例子很容易让人理解。
- [关于word_embedding](https://www.zhihu.com/question/32275069) 从one hot 到 word2vec的演变。其实后面BERT、ELmo等各种表示层出不穷。
- [关于激活函数](https://www.zhihu.com/question/22334626)  激活函数的核心：将原来只能拟合线性函数的神经网络，摇身一变，可以拟合非线性函数，这样达到可以拟合任意函数的效果了。
- [文本分类的优秀示例](https://zhuanlan.zhihu.com/p/28923961) 这是一篇知乎看山杯的比赛夺冠记录，里面将常用文本分类模型都介绍了一遍，非常值得学习。
- [详解MNIST数据集](deeplearning\详解MNIST数据集.pdf) 图像识别demo，或者CNN的demo绝对绕不开这个手写数字识别数据集，超级经典。
- [LSTM经典解读博客](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) 这个是英文原版的，也可以看[中文翻译版](https://blog.csdn.net/qiu931110/article/details/69400501)。
- [RNN到LSTM最清晰易懂的视频](deeplearning\RNN到LSTM最清晰易懂的视频.pdf) 这里面提到的视频和博客是我见过关于【RNN到LSTM演变】讲的最清晰的。
- [关于BatchNormalization精华解读](deeplearning\BatchNormalization.pdf) 这是我从知乎回答里精选的内容，概括了BatchNormalization的本质。
- [各种优化器的区别](deeplearning\各种优化器的区别.pdf) 各种优化器，SGD、Adam是不是把你搞晕了，这里能解答你的疑惑。
- [Encoder-Decoder模型笔记](deeplearning\Encoder-Decoder模型笔记.pdf) 非常简洁，10分钟就能理解。
- [BiLSTM-CRF最清晰易懂的解读](https://github.com/createmomo/CRF-Layer-on-the-Top-of-BiLSTM) 这里面分了几个小部分，拆分讲解，生动形象，英文很容易懂，别怕，学会英文自由阅读就再也不怕被错误翻译给误导了有木有。
- [Transformer最佳解读-英文](https://jalammar.github.io/illustrated-transformer/) 中文版的可以参考[夏目博客](https://blog.csdn.net/qq_41664845/article/details/84969266)。还可参考[张俊林谈Attention](https://blog.csdn.net/malefactor/article/details/78767781) 和 [《Attention is All You Need》浅读（简介+代码）](https://kexue.fm/archives/4765)。
- [Transformer实战]([https://wbbeyourself.github.io/2019/07/22/Transformer%E5%AE%9E%E6%88%98/](https://wbbeyourself.github.io/2019/07/22/Transformer实战/)) 这是我的博客，一行一行代码分析解读，超级详细。
- [关于Attention Model及其本质](https://blog.csdn.net/malefactor/article/details/50550211) 一文搞懂Attention的本质。
- [Seq2Seq详解](https://blog.csdn.net/Jerr__y/article/details/53749693) 揭开风靡一时的Seq2Seq的神秘面纱。
- [BERT学习](deeplearning\BERT学习.pdf) BERT学习相关链接汇总。
- [pandas常用api](deeplearning\pandas常用api.pdf)  pandas常用的api汇总。
- [关于深度学习的困惑](deeplearning\关于深度学习的困惑.pdf) 我的一些困惑，估计大家也会遇到，慢慢来，见多了就熟悉了，就会自己搞模型了。




## 自然语言处理



## 编程相关

- 11

## 论文写作

- [以AM为例谈谈两种研究创新模式](https://blog.csdn.net/malefactor/article/details/50583474) 分别是：应用创新（已有模型引入到新任务）；模型创新（对模型本身的改进）。

## 其他






